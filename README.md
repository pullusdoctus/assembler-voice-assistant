# Assembler Voice Assistant

Un asistente de voz mÃ­nimo programado en C++ y x86 Assembly.

<p align="center">
  <img src="assets/screenshot.png" alt="UI del asistente"/>
</p>

El propÃ³sito de este proyecto es demostrar cÃ³mo la programaciÃ³n de bajo nivel puede integrarse con tecnologÃ­as de mÃ¡s alto nivel con el fin de crear aplicaciones prÃ¡cticas.

---

## ğŸ§  Funcionalidades principales

- Reconocimiento de voz local con [PocketSphinx](https://github.com/cmusphinx/pocketsphinx)
- Interfaz grÃ¡fica con GTK3
- ComunicaciÃ³n con un LLM local (DeepSeek) mediante una API
- Comandos por voz simples y respuesta textual
- Componentes escritos en C++ y x86 Assembly

---

## ğŸ“ Estructura del proyecto

```
.
â”œâ”€â”€ src/             # CÃ³digo fuente en C++ y ASM
â”œâ”€â”€ obj/             # Archivos objeto generados
â”œâ”€â”€ assets/          # Recursos grÃ¡ficos y fuentes
â”œâ”€â”€ Makefile         # Script de compilaciÃ³n
â””â”€â”€ README.md        # Este archivo

````

---

## ğŸ§° Requisitos

- Sistema operativo: Linux x86_64
- NASM (ensamblador)
- g++ (compilador C++)
- GTK3
- PulseAudio
- PocketSphinx
- Docker + Ollama
- Node.js + npm (para la API)

---

## ğŸ“¦ InstalaciÃ³n de dependencias en Ubuntu/Debian

```bash
sudo apt update
sudo apt install \
  build-essential nasm g++ \
  libgtk-3-dev \
  pulseaudio \
  pocketsphinx pocketsphinx-en-us
````

---

## ğŸ› ï¸ CompilaciÃ³n

Desde la raÃ­z del proyecto:

```bash
make
```

Esto generarÃ¡ el ejecutable `voice_assistant` en el directorio actual.

---

## ğŸš€ EjecuciÃ³n

### 1. Iniciar el modelo DeepSeek

Para que el asistente se comunique con el modelo, primero debe iniciar la API y el modelo LLM localmente.

#### a. Clonar la API

```bash
git clone https://github.com/Sleyter28/assembler-recognizer-be
cd assembler-recognizer-be
```

#### b. Instalar dependencias y modelo con Docker

```bash
docker compose up  # Inicia el contenedor con DeepSeek y Ollama
```

#### c. Iniciar el servidor de la API

En otra terminal:

```bash
npm install
npm run dev
```

La API se ejecutarÃ¡ en `http://localhost:3000/api`.

---

### 2. Iniciar el asistente

En la raÃ­z del proyecto:

```bash
./voice_assistant
```

Al ejecutar el binario, se abrirÃ¡ una ventana con la interfaz. El asistente escucharÃ¡ comandos por voz y enviarÃ¡ la transcripciÃ³n al modelo LLM para su interpretaciÃ³n. TambiÃ©n se puede enviar el prompt como texto directamente.

---

## ğŸ§ª Prueba de API con Postman

Para verificar si el backend estÃ¡ funcionando correctamente:

1. Abrir [Postman](https://www.postman.com/)
2. Hacer una solicitud `POST` a:
   `http://localhost:3000/api/ollama/deepseek`
3. En el cuerpo JSON, enviar algo como:

```json
{
  "prompt": "Â¿CuÃ¡l es la capital de Francia?",
  "model": "deepseek-r1:1.5b"
}
```

---

## ğŸ Problemas comunes

| Error                                             | SoluciÃ³n                                                                                    |
| ------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| `docker: command not found`                       | Instalar Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/) |
| `Error: pull model manifest: file does not exist` | AsegÃºrese de tener el modelo cargado en Ollama (`ollama run deepseek`)                      |
| GTK error al lanzar                               | Verifique que `libgtk-3-dev` estÃ¡ correctamente instalado                                   |
| No detecta micrÃ³fono                              | Confirme que PulseAudio estÃ¡ corriendo (`pulseaudio --start`)                               |

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ licenciado bajo la [MIT License](./LICENSE).

---

## ğŸ‘¤ CrÃ©ditos

* [@doctuspullus](https://github.com/doctuspullus)
* [@YiYhuan](https://github.com/YiYhuan)
* [Sleyter28](https://github.com/Sleyter28) â€” API para conectar con una instancia local de DeepSeek

---
